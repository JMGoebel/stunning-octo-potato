{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import StorageContext, load_index_from_storage\n",
    "from constants import embed_model\n",
    "\n",
    "storage_context = StorageContext.from_defaults(persist_dir='index/')\n",
    "index = load_index_from_storage(storage_context, embed_model=embed_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.tools import QueryEngineTool\n",
    "from constants import llm_model \n",
    "\n",
    "query_engine = index.as_query_engine(llm=llm_model, simularity_top_k=5)\n",
    "\n",
    "rag_tool = QueryEngineTool.from_defaults(\n",
    "  query_engine,\n",
    "  name='research_paper_query_engine_tool',\n",
    "  description='A RAG tool for querying research papers'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "def display_prompt_dict(prompts_dict):\n",
    "    for key, prompt in prompts_dict.items():\n",
    "        display(Markdown(f\"**Prompt key**: {key}\"))\n",
    "        print(prompt.get_template())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_dict = query_engine.get_prompts()\n",
    "display_prompt_dict(prompt_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools import download_pdf, fetch_arxiv_papers\n",
    "from llama_index.core.tools import FunctionTool\n",
    "\n",
    "download_pdf_tool = FunctionTool.from_defaults(download_pdf, name='download_pdf_file_tool', description='A tool to download pdfs')\n",
    "fetch_arxiv_papers_tool = FunctionTool.from_defaults(fetch_arxiv_papers, name='fetch_arxiv_papers_tool', description='A tool to fetch arxiv papers')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.agent import ReActAgent\n",
    "from constants import llm_model \n",
    "\n",
    "agent = ReActAgent.from_tools(\n",
    "  [rag_tool, download_pdf_tool, fetch_arxiv_papers_tool],\n",
    "  name='research_paper_query_tool',\n",
    "  description='An agent for querying research papers',\n",
    "  llm=llm_model,\n",
    "  verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_template = \"\"\"I am interested in the topic of {topic}.\n",
    "Find papers in your knowledge databse to this topic.\n",
    "Use the following template to query research_paper_query_tool tool:\n",
    "'Provide title, summary, authers and link to download for papers related to {topic}'\n",
    "If there are not, could you fetch the recent one from arxiv\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = agent.chat(query_template.format(topic='Role Playing Games'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.tools import QueryEngineTool\n",
    "from constants import llm_model \n",
    "\n",
    "query_engine = index.as_query_engine(llm=llm_model, simularity_top_k=5)\n",
    "\n",
    "result = query_engine.query('How can LLM be used in a role playing game')\n",
    "\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
